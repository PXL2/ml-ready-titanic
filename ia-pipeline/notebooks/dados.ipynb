{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "url = \"../data/raw/Titanic-Dataset.csv\"\n",
    "data = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE EXPLORATÓRIA COMPLETA ===\n",
      "\n",
      "--- Análise das Cabines por Classe ---\n",
      "\n",
      "Cabines registradas por classe:\n",
      "Pclass\n",
      "1    176\n",
      "2     16\n",
      "3     12\n",
      "Name: Cabin, dtype: int64\n",
      "\n",
      "Letras de cabine por classe:\n",
      "Cabin_Letter   A   B   C   D   E  F  G  T  Unknown\n",
      "Pclass                                            \n",
      "1             15  47  59  29  25  0  0  1       40\n",
      "2              0   0   0   4   4  8  0  0      168\n",
      "3              0   0   0   0   3  5  4  0      479\n",
      "\n",
      "--- Análise de Títulos ---\n",
      "\n",
      "Distribuição de títulos:\n",
      "Title\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Rare       27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Análise Familiar ---\n",
      "\n",
      "Sobrevivência por tamanho de família:\n",
      "Family_Size\n",
      "1     0.30\n",
      "2     0.55\n",
      "3     0.58\n",
      "4     0.72\n",
      "5     0.20\n",
      "6     0.14\n",
      "7     0.33\n",
      "8     0.00\n",
      "11    0.00\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurar pandas para mostrar 2 casas decimais\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# =============================================\n",
    "# 1. ANÁLISE EXPLORATÓRIA APRIMORADA\n",
    "# =============================================\n",
    "print(\"\\n=== ANÁLISE EXPLORATÓRIA COMPLETA ===\")\n",
    "\n",
    "# 1.1. Análise de Cabines\n",
    "print(\"\\n--- Análise das Cabines por Classe ---\")\n",
    "data['Cabin_Letter'] = data['Cabin'].str[0].fillna('Unknown')\n",
    "print(\"\\nCabines registradas por classe:\")\n",
    "print(data.groupby('Pclass')['Cabin'].count())\n",
    "print(\"\\nLetras de cabine por classe:\")\n",
    "print(data.groupby(['Pclass', 'Cabin_Letter']).size().unstack(fill_value=0))\n",
    "\n",
    "# 1.2. Análise de Títulos\n",
    "print(\"\\n--- Análise de Títulos ---\")\n",
    "data['Title'] = data['Name'].str.extract(r',\\s([A-Za-z]+)\\.', expand=False)\n",
    "common_titles = ['Mr', 'Mrs', 'Miss', 'Master']\n",
    "data['Title'] = data['Title'].apply(lambda x: x if x in common_titles else 'Rare')\n",
    "print(\"\\nDistribuição de títulos:\")\n",
    "print(data['Title'].value_counts())\n",
    "\n",
    "# 1.3. Análise Familiar\n",
    "print(\"\\n--- Análise Familiar ---\")\n",
    "data['Family_Size'] = data['SibSp'] + data['Parch'] + 1\n",
    "data['Is_Alone'] = (data['Family_Size'] == 1).astype(int)\n",
    "print(\"\\nSobrevivência por tamanho de família:\")\n",
    "print(data.groupby('Family_Size')['Survived'].mean().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores faltantes após limpeza:\n",
      "Age                  0\n",
      "SibSp                0\n",
      "Parch                0\n",
      "Fare                 0\n",
      "Has_Cabin            0\n",
      "Family_Size          0\n",
      "Is_Alone             0\n",
      "Sex_male             0\n",
      "Embarked_Q           0\n",
      "Embarked_S           0\n",
      "Pclass_2             0\n",
      "Pclass_3             0\n",
      "Title_Miss           0\n",
      "Title_Mr             0\n",
      "Title_Mrs            0\n",
      "Title_Rare           0\n",
      "Age_Group_Teen       0\n",
      "Age_Group_Adult      0\n",
      "Age_Group_Elderly    0\n",
      "Fare_Group_Q2        0\n",
      "Fare_Group_Q3        0\n",
      "Fare_Group_Q4        0\n",
      "dtype: int64\n",
      "\n",
      "Dados aprimorados para modelagem (5 primeiras linhas):\n",
      "    Age  SibSp  Parch  ...  Fare_Group_Q2  Fare_Group_Q3  Fare_Group_Q4\n",
      "0  22.0      1      0  ...          False          False          False\n",
      "1  38.0      1      0  ...          False          False           True\n",
      "2  26.0      0      0  ...           True          False          False\n",
      "3  35.0      1      0  ...          False          False           True\n",
      "4  35.0      0      0  ...           True          False          False\n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Taxa de sobrevivência por título:\n",
      "Title\n",
      "Master    0.57\n",
      "Miss      0.70\n",
      "Mr        0.16\n",
      "Mrs       0.79\n",
      "Rare      0.44\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 3. APLICAÇÃO E VERIFICAÇÃO\n",
    "# =============================================\n",
    "# Aplicar pré-processamento\n",
    "X_enhanced, y_enhanced = prepare_enhanced_data(data.copy())\n",
    "\n",
    "# Verificar dados finais\n",
    "print(\"\\nDados aprimorados para modelagem (5 primeiras linhas):\")\n",
    "print(X_enhanced.head())\n",
    "\n",
    "# Mostrar taxa de sobrevivência por novas features\n",
    "print(\"\\nTaxa de sobrevivência por título:\")\n",
    "print(data.groupby('Title')['Survived'].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 120 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n120 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 562, in _fit\n    self._validate_steps()\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 339, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 83\u001b[0m\n\u001b[0;32m     74\u001b[0m model \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     75\u001b[0m     pipeline,\n\u001b[0;32m     76\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# 4. Treinamento no conjunto de treino\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# 5. Melhor combinação de hiperparâmetros\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMelhores hiperparâmetros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 120 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n120 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 562, in _fit\n    self._validate_steps()\n  File \"C:\\Users\\pepeh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 339, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n"
     ]
    }
   ],
   "source": [
    "#treinar o modelo  com dados reais \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prepare_enhanced_data(df):\n",
    "    # 2.1. Tratar dados faltantes\n",
    "    df['Age'] = df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    \n",
    "    # 2.2. Feature Engineering\n",
    "    df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['Is_Alone'] = (df['Family_Size'] == 1).astype(int)\n",
    "    \n",
    "    # 2.3. Discretização\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=[0, 12, 18, 60, 100], \n",
    "                            labels=['Child', 'Teen', 'Adult', 'Elderly'])\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    # 2.4. Tratar outliers\n",
    "    fare_upper_limit = df['Fare'].quantile(0.95)\n",
    "    df['Fare'] = np.where(df['Fare'] > fare_upper_limit, fare_upper_limit, df['Fare'])\n",
    "    \n",
    "    # 2.5. Converter variáveis categóricas\n",
    "    df = pd.get_dummies(df, columns=[\n",
    "        'Sex', 'Embarked', 'Pclass', 'Title', 'Age_Group', 'Fare_Group'\n",
    "    ], drop_first=True)\n",
    "    \n",
    "    # 2.6. Selecionar features\n",
    "    features = [\n",
    "        'Age', 'SibSp', 'Parch', 'Fare', 'Has_Cabin', 'Family_Size', 'Is_Alone',\n",
    "        'Sex_male', 'Embarked_Q', 'Embarked_S', \n",
    "        'Pclass_2', 'Pclass_3',\n",
    "        'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare',\n",
    "        'Age_Group_Teen', 'Age_Group_Adult', 'Age_Group_Elderly',\n",
    "        'Fare_Group_Q2', 'Fare_Group_Q3', 'Fare_Group_Q4'\n",
    "    ]\n",
    "    \n",
    "    # 2.7. Verificar dados faltantes\n",
    "    print(\"\\nValores faltantes após limpeza:\")\n",
    "    print(df[features].isnull().sum())\n",
    "    \n",
    "    return df[features], df['Survived']\n",
    "\n",
    "# Dividimos os dados em [treino (70%), validação (15%) e teste (15%)]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_enhanced, y_enhanced, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# --- Estratégias Anti-Overfitting ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Hiperparâmetros para RandomForest\n",
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Modelo com GridSearchCV\n",
    "model = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar com dados balanceados\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros\n",
    "print(\"\\nMelhores hiperparâmetros:\", model.best_params_)\n",
    "\n",
    "\n",
    "# --- Avaliação no Conjunto de Validação ---\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"\\nRelatório no conjunto de VALIDAÇÃO:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# --- Avaliação Final no Teste ---\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"\\nRelatório no conjunto de TESTE:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[\"Não Sobreviveu\", \"Sobreviveu\"]\n",
    ")# Aplicar SMOTE para balancear as classes no conjunto de treino\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Matriz de Confusão (Teste) - Titanic\")\n",
    "plt.show()\n",
    "\n",
    "# --- Curva de Aprendizado para Diagnóstico ---\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "# Utilizando pld para gráficos para matriz de confusão e cuva de aprendizado\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label=\"Treino\")\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label=\"Validação\")\n",
    "plt.xlabel(\"Tamanho do Conjunto de Treino\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Curva de Aprendizado\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
