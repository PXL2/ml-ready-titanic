# PrÃ©-processamento do Dataset Titanic

Este projeto realiza uma anÃ¡lise exploratÃ³ria completa e prÃ©-processamento do dataset Titanic, preparando os dados para modelos preditivos de machine learning. O trabalho foi desenvolvido em colaboraÃ§Ã£o por Pedro Lima e Carla Santana.

## âœ¨ Principais Funcionalidades

Aqui estÃ£o detalhadas as principais transformaÃ§Ãµes e tÃ©cnicas aplicadas aos dados:

### ğŸ§¹ Limpeza de Dados
* Tratamento de valores faltantes em `Age`, `Embarked` e `Cabin`.
* RemoÃ§Ã£o de outliers na tarifa (`Fare`). *(Nota: Esta etapa pode precisar ser verificada em relaÃ§Ã£o aos scripts que geramos, que focaram mais na imputaÃ§Ã£o robusta).*

### ğŸ› ï¸ Engenharia de Features
* CriaÃ§Ã£o da feature `Tamanho_Familia` a partir de `SibSp` e `Parch`.
* AdiÃ§Ã£o da feature binÃ¡ria `Sozinho` para indicar passageiros viajando sozinhos.
* ExtraÃ§Ã£o e normalizaÃ§Ã£o da feature `Titulo` a partir dos nomes dos passageiros.

### âš–ï¸ Balanceamento de Classes
Para lidar com o desbalanceamento na variÃ¡vel alvo (`Survived`), utilizamos a tÃ©cnica SMOTE (Synthetic Minority Over-sampling Technique) no conjunto de treinamento. Isso ajuda a previnir que o modelo de machine learning seja enviesado em direÃ§Ã£o Ã  classe majoritÃ¡ria.

**Antes do SMOTE:**
A distribuiÃ§Ã£o original da variÃ¡vel alvo no conjunto de treino mostra um desbalanceamento entre as classes "NÃ£o Sobreviveu" e "Sobreviveu".

![DistribuiÃ§Ã£o da VariÃ¡vel Alvo (y_train) - ANTES do SMOTE](assets/images/distribuicao_antes_smote.png)
*Figura 1: DistribuiÃ§Ã£o da variÃ¡vel alvo antes da aplicaÃ§Ã£o do SMOTE.*


**Depois do SMOTE:**
ApÃ³s a aplicaÃ§Ã£o do SMOTE, as classes no conjunto de treino ficam balanceadas.

![DistribuiÃ§Ã£o da VariÃ¡vel Alvo (y_train_smote) - DEPOIS do SMOTE](assets/images/distribuicao_depois_smote.png)
*Figura 2: DistribuiÃ§Ã£o da variÃ¡vel alvo apÃ³s a aplicaÃ§Ã£o do SMOTE.*

### ğŸ”¡ CodificaÃ§Ã£o
* TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas (`Sex`, `Embarked`, `Pclass`, `Title`) em formato numÃ©rico adequado para os algoritmos de machine learning. *(Nos scripts que geramos, usamos principalmente LabelEncoding seguido de StandardScaler no pipeline de treino).*

## ğŸ“ Estrutura do Projeto
titanic-preprocess/
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ brutos/
â”‚   â”‚   â””â”€â”€ Titanic-Dataset.csv  # Dataset original
â”‚   â””â”€â”€ processados/
â”‚       â””â”€â”€ processed_titanic_data.csv # Dados limpos e prÃ©-processados (gerado por processados.py)
â”œâ”€â”€ ia-pipeline/ # (Se vocÃª estiver usando a estrutura que definimos para os scripts Python)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â””â”€â”€ Titanic-Dataset.csv
â”‚   â”‚   â””â”€â”€ processed/
â”‚   â”‚       â”œâ”€â”€ processados.py
â”‚   â”‚       â”œâ”€â”€ processed_titanic_data.csv
â”‚   â”‚       â””â”€â”€ treino/
â”‚   â”‚           â””â”€â”€ train.py
â”‚   â”œâ”€â”€ models/ # Modelos treinados
â”‚   â””â”€â”€ models_cache/ # Cache do GridSearchCV
â”œâ”€â”€ notebooks/          # Jupyter notebooks para anÃ¡lise exploratÃ³ria e desenvolvimento inicial
â”‚   â””â”€â”€ dados.ipynb
â”œâ”€â”€ src/                # Scripts Python (se estiver usando a estrutura da imagem do README original)
â”‚   â””â”€â”€ preprocess.py   # (Ajustar conforme a localizaÃ§Ã£o real dos seus scripts)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
